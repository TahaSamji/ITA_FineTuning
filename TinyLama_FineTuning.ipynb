{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"\nfrom datasets import load_dataset\nfrom transformers import AutoTokenizer, AutoModelForCausalLM, DataCollatorForLanguageModeling, TrainingArguments, Trainer, TrainerCallback\nfrom peft import LoraConfig, TaskType, get_peft_model\nimport torch\nimport psutil\nimport numpy as np\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T19:03:05.955776Z","iopub.execute_input":"2025-06-09T19:03:05.956048Z","iopub.status.idle":"2025-06-09T19:03:35.826031Z","shell.execute_reply.started":"2025-06-09T19:03:05.956024Z","shell.execute_reply":"2025-06-09T19:03:35.825326Z"}},"outputs":[{"name":"stderr","text":"2025-06-09 19:03:21.435321: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1749495801.660749      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1749495801.725468      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# !pip install trl","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T19:03:35.826740Z","iopub.execute_input":"2025-06-09T19:03:35.827256Z","iopub.status.idle":"2025-06-09T19:03:35.830833Z","shell.execute_reply.started":"2025-06-09T19:03:35.827235Z","shell.execute_reply":"2025-06-09T19:03:35.830020Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"torch.cuda.set_per_process_memory_fraction(1.0, 0)  # Use maximum available memory\ntorch.cuda.memory_max_split_size_mb = 64  # Set the max split size to avoid fragmentation","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T19:03:35.832565Z","iopub.execute_input":"2025-06-09T19:03:35.832768Z","iopub.status.idle":"2025-06-09T19:03:36.016836Z","shell.execute_reply.started":"2025-06-09T19:03:35.832753Z","shell.execute_reply":"2025-06-09T19:03:36.016030Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"def print_memory_footprint():\n    # GPU memory usage\n    if torch.cuda.is_available():\n        gpu_memory = torch.cuda.memory_allocated() / (1024 ** 3)  # Convert to GB\n        gpu_memory_cached = torch.cuda.memory_reserved() / (1024 ** 3)  # Cached memory\n        print(f\"[GPU] Memory Allocated: {gpu_memory:.2f} GB, Cached: {gpu_memory_cached:.2f} GB\")\n    else:\n        print(\"[GPU] No GPU detected.\")\n\n    # CPU memory usage\n    memory = psutil.virtual_memory()\n    used_memory_gb = memory.used / (1024 ** 3)  # Convert to GB\n    total_memory_gb = memory.total / (1024 ** 3)\n    print(f\"[CPU] Memory Usage: {used_memory_gb:.2f} GB / {total_memory_gb:.2f} GB\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T19:03:36.017584Z","iopub.execute_input":"2025-06-09T19:03:36.017821Z","iopub.status.idle":"2025-06-09T19:03:36.032008Z","shell.execute_reply.started":"2025-06-09T19:03:36.017804Z","shell.execute_reply":"2025-06-09T19:03:36.031379Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"'''\nprint(\"First example of blended_skill_talk training set:\")\nprint(dataset['train'][0])\n'''","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T19:03:36.032832Z","iopub.execute_input":"2025-06-09T19:03:36.033380Z","iopub.status.idle":"2025-06-09T19:03:36.046861Z","shell.execute_reply.started":"2025-06-09T19:03:36.033344Z","shell.execute_reply":"2025-06-09T19:03:36.046228Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"'\\nprint(\"First example of blended_skill_talk training set:\")\\nprint(dataset[\\'train\\'][0])\\n'"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\")\ntokenizer.pad_token = tokenizer.eos_token  # GPT-2 doesn't have a pad token, so we use eos_token","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T19:03:36.047520Z","iopub.execute_input":"2025-06-09T19:03:36.047677Z","iopub.status.idle":"2025-06-09T19:03:37.008578Z","shell.execute_reply.started":"2025-06-09T19:03:36.047664Z","shell.execute_reply":"2025-06-09T19:03:37.008086Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/1.29k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fbbd36ecc0b84816b23f5ca4c4608a4d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a05e2398202c434fa35de9e5a21dff35"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"40eada17c5f04424a1eed13f2c3a5b24"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/551 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c3f24836446a4110ba4f0681ca8ad32e"}},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"# Load dataset and tokenizer\ndataset = load_dataset(\"allenai/soda\")\n\n\n\ndef tokenize_function(examples):\n    # Concatenate dialog turns into a single string for language modeling\n    texts = [\" \".join(dialog) for dialog in examples[\"dialogue\"]]\n    return tokenizer(texts, truncation=True, max_length=512)\n\n# Tokenize datasets\ntokenized_datasets = dataset.map(tokenize_function, batched=True, remove_columns=['head', 'relation', 'tail', 'literal', 'narrative', 'dialogue', 'speakers', 'PersonX', 'PersonY', 'PersonZ', 'original_index', 'split', 'head_answer', 'pmi_head_answer', 'relation_tail_answer', 'pmi_relation_tail_answer'])\nsmall_train_dataset = tokenized_datasets[\"train\"].shuffle(seed=42).select(range(2500))\nsmall_eval_dataset = tokenized_datasets[\"validation\"].shuffle(seed=42).select(range(500))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T19:03:37.009183Z","iopub.execute_input":"2025-06-09T19:03:37.009381Z","iopub.status.idle":"2025-06-09T19:09:13.050419Z","shell.execute_reply.started":"2025-06-09T19:03:37.009364Z","shell.execute_reply":"2025-06-09T19:09:13.049642Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/4.92k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"55c068d39765427b91dcdc2ea2ce57b2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train.parquet:   0%|          | 0.00/689M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4cb3ae18a2d94c43834b8cf17d3568a7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"valid.parquet:   0%|          | 0.00/82.9M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5ba66c9d7dda4862887946026a5b78ee"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"test.parquet:   0%|          | 0.00/84.2M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eae98b5a151f4ab89f08ddb7fa623553"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/1191582 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"568272bc8af84ad68d468a112b6f43d7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/146346 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"16489bcce20a4486939d1c5379948b86"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/148968 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dfa64556642f4c62a8c99d0b22eee076"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1191582 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b97e07a8fb6a44b884f07add86a0cb46"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/146346 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dc4d29e1f2e64270a6393e90e6abf2f4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/148968 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"20f9348ccb364befb36739c5e402c1bb"}},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"print(dataset)\ntokenized_datasets\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T19:09:13.051330Z","iopub.execute_input":"2025-06-09T19:09:13.051600Z","iopub.status.idle":"2025-06-09T19:09:13.057285Z","shell.execute_reply.started":"2025-06-09T19:09:13.051576Z","shell.execute_reply":"2025-06-09T19:09:13.056543Z"}},"outputs":[{"name":"stdout","text":"DatasetDict({\n    train: Dataset({\n        features: ['head', 'relation', 'tail', 'literal', 'narrative', 'dialogue', 'speakers', 'PersonX', 'PersonY', 'PersonZ', 'original_index', 'split', 'head_answer', 'pmi_head_answer', 'relation_tail_answer', 'pmi_relation_tail_answer'],\n        num_rows: 1191582\n    })\n    validation: Dataset({\n        features: ['head', 'relation', 'tail', 'literal', 'narrative', 'dialogue', 'speakers', 'PersonX', 'PersonY', 'PersonZ', 'original_index', 'split', 'head_answer', 'pmi_head_answer', 'relation_tail_answer', 'pmi_relation_tail_answer'],\n        num_rows: 146346\n    })\n    test: Dataset({\n        features: ['head', 'relation', 'tail', 'literal', 'narrative', 'dialogue', 'speakers', 'PersonX', 'PersonY', 'PersonZ', 'original_index', 'split', 'head_answer', 'pmi_head_answer', 'relation_tail_answer', 'pmi_relation_tail_answer'],\n        num_rows: 148968\n    })\n})\n","output_type":"stream"},{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['input_ids', 'attention_mask'],\n        num_rows: 1191582\n    })\n    validation: Dataset({\n        features: ['input_ids', 'attention_mask'],\n        num_rows: 146346\n    })\n    test: Dataset({\n        features: ['input_ids', 'attention_mask'],\n        num_rows: 148968\n    })\n})"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"# LoRA configuration for causal language modeling\nlora_config = LoraConfig(\n    task_type=TaskType.CAUSAL_LM,\n    r=8,\n    lora_alpha=32,\n    lora_dropout=0.09,\n    target_modules=[\"q_proj\",\"v_proj\",\"up_proj\"],\n)\n\n# %%","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T19:09:13.059812Z","iopub.execute_input":"2025-06-09T19:09:13.060046Z","iopub.status.idle":"2025-06-09T19:09:13.546460Z","shell.execute_reply.started":"2025-06-09T19:09:13.060028Z","shell.execute_reply":"2025-06-09T19:09:13.545766Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"# Dynamic device assignment\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n# Load pre-trained GPT-2 language model\n# Load pre-trained GPT-2 model\n#model = GPT2LMHeadModel.from_pretrained(\"gpt2\", pad_token_id=tokenizer.eos_token_id).to(device)\nmodel = AutoModelForCausalLM.from_pretrained(\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\",\n                                             torch_dtype=torch.bfloat16,).to(device)\n\n# Apply LoRA to the model\nmodel = get_peft_model(model, lora_config)\n\n# Enable gradient checkpointing if you run into memory issues\n#model.gradient_checkpointing_enable()\n\n# %%\n# Print the model's architecture to inspect the names of the modules\n#print(model)\n\n# %%\nprint_memory_footprint()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T19:09:13.547078Z","iopub.execute_input":"2025-06-09T19:09:13.547322Z","iopub.status.idle":"2025-06-09T19:09:24.202683Z","shell.execute_reply.started":"2025-06-09T19:09:13.547296Z","shell.execute_reply":"2025-06-09T19:09:24.202045Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/608 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5462766612e3475b8ea4e1241d204cfa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/2.20G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ca865bec0c8a4d618d79f3cf19b6e137"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"efa67905411342c9897e6936fb5ce3fa"}},"metadata":{}},{"name":"stdout","text":"[GPU] Memory Allocated: 2.06 GB, Cached: 2.15 GB\n[CPU] Memory Usage: 2.27 GB / 31.35 GB\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"# %%\n\n# Data collator for language modeling (masks tokens for prediction)\ndata_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False) # mlm=False for causal LM\n\n# Perplexity as metric\n#perplexity_metric = evaluate.load(\"perplexity\", module_type=\"metric\")\n\ndef compute_metrics(eval_pred):\n    logits, labels = eval_pred\n    shift_logits = torch.tensor(logits[:, :-1, :])\n    shift_labels = torch.tensor(labels[:, 1:])\n    loss_fct = torch.nn.CrossEntropyLoss(ignore_index=-100)\n    loss = loss_fct(shift_logits.view(-1, shift_logits.size(-1)), shift_labels.view(-1))\n    ppl = torch.exp(loss).item()\n    return {\"perplexity\": ppl}\n\n# Training args\ntraining_args = TrainingArguments(\n    output_dir=\"./lama-dialog-finetuned\",\n    per_device_train_batch_size=4,\n    per_device_eval_batch_size=2,\n    num_train_epochs=4,\n    learning_rate=5e-5,\n    logging_dir=\"./logs\",\n    logging_steps=100,\n    #evaluation_strategy=\"epoch\",\n    #save_strategy=\"epoch\",\n    report_to=\"none\",\n    remove_unused_columns=False,\n    bf16=True,  # Enable bfloat16\n    fp16=False,  # Disable fp16 to avoid conflicts\n)\n# %%\nprint_memory_footprint()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T19:09:24.203450Z","iopub.execute_input":"2025-06-09T19:09:24.204341Z","iopub.status.idle":"2025-06-09T19:09:24.240153Z","shell.execute_reply.started":"2025-06-09T19:09:24.204314Z","shell.execute_reply":"2025-06-09T19:09:24.239512Z"}},"outputs":[{"name":"stdout","text":"[GPU] Memory Allocated: 2.06 GB, Cached: 2.15 GB\n[CPU] Memory Usage: 2.28 GB / 31.35 GB\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"class MemoryCallback(TrainerCallback):\n    def on_evaluate(self, args, state, control, **kwargs):\n        print(\"\\nMemory footprint after evaluation:\")\n        print_memory_footprint()\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=small_train_dataset,\n    #eval_dataset=small_eval_dataset,\n    tokenizer=tokenizer,\n    data_collator=data_collator,\n    #compute_metrics=compute_metrics,\n    callbacks=[MemoryCallback()]\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T19:09:24.240891Z","iopub.execute_input":"2025-06-09T19:09:24.241203Z","iopub.status.idle":"2025-06-09T19:09:24.279379Z","shell.execute_reply.started":"2025-06-09T19:09:24.241185Z","shell.execute_reply":"2025-06-09T19:09:24.278718Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_35/3187942852.py:6: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  trainer = Trainer(\nNo label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"any(p.requires_grad for p in model.parameters())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T19:09:24.280164Z","iopub.execute_input":"2025-06-09T19:09:24.280384Z","iopub.status.idle":"2025-06-09T19:09:24.284933Z","shell.execute_reply.started":"2025-06-09T19:09:24.280362Z","shell.execute_reply":"2025-06-09T19:09:24.284268Z"}},"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"trainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T19:09:24.285649Z","iopub.execute_input":"2025-06-09T19:09:24.285969Z","iopub.status.idle":"2025-06-09T20:03:53.960423Z","shell.execute_reply.started":"2025-06-09T19:09:24.285951Z","shell.execute_reply":"2025-06-09T20:03:53.959842Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1252' max='1252' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1252/1252 54:26, Epoch 4/4]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>100</td>\n      <td>0.731500</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>0.682800</td>\n    </tr>\n    <tr>\n      <td>300</td>\n      <td>0.692800</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>0.642900</td>\n    </tr>\n    <tr>\n      <td>500</td>\n      <td>0.635800</td>\n    </tr>\n    <tr>\n      <td>600</td>\n      <td>0.628700</td>\n    </tr>\n    <tr>\n      <td>700</td>\n      <td>0.622600</td>\n    </tr>\n    <tr>\n      <td>800</td>\n      <td>0.619900</td>\n    </tr>\n    <tr>\n      <td>900</td>\n      <td>0.630200</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>0.636300</td>\n    </tr>\n    <tr>\n      <td>1100</td>\n      <td>0.616200</td>\n    </tr>\n    <tr>\n      <td>1200</td>\n      <td>0.619100</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=1252, training_loss=0.6459459877623537, metrics={'train_runtime': 3269.2652, 'train_samples_per_second': 3.059, 'train_steps_per_second': 0.383, 'total_flos': 1.838161000562688e+16, 'train_loss': 0.6459459877623537, 'epoch': 4.0})"},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"trainer.save_model('TinyLlama-new-1000')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T20:03:53.961117Z","iopub.execute_input":"2025-06-09T20:03:53.961386Z","iopub.status.idle":"2025-06-09T20:03:54.159265Z","shell.execute_reply.started":"2025-06-09T20:03:53.961368Z","shell.execute_reply":"2025-06-09T20:03:54.158714Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"print_memory_footprint()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T20:03:54.159876Z","iopub.execute_input":"2025-06-09T20:03:54.160136Z","iopub.status.idle":"2025-06-09T20:03:54.164682Z","shell.execute_reply.started":"2025-06-09T20:03:54.160114Z","shell.execute_reply":"2025-06-09T20:03:54.163934Z"}},"outputs":[{"name":"stdout","text":"[GPU] Memory Allocated: 2.09 GB, Cached: 10.98 GB\n[CPU] Memory Usage: 2.91 GB / 31.35 GB\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\nsmoothie = SmoothingFunction().method4\n# Dynamic device assignment\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n# For generation, we'll load the model and use the `generate` method\nmodel_for_generation = AutoModelForCausalLM.from_pretrained('TinyLlama-new-1000').to(device)\n#model_for_generation = get_peft_model(model_for_generation, lora_config) # Ensure LoRA is applied\n\ninput_texts = [\n    \"So light is made up of colors?\",\n    \"Why is the sky blue?\",\n    \"How does gravity work?\",\n    \"What causes rainbows?\",\n    \"Why do we see lightning before thunder?\",\n    \"How do plants make food?\",\n    \"Why do we sleep?\",\n    \"What is photosynthesis?\",\n    \"How does the internet work?\",\n    \"Why do birds migrate?\"\n]\n\nreference_answers = [\n    \"Yes, light is made up of different colors. When they combine, they appear white. This can be separated with prisms, for example.\",\n    \"The sky appears blue due to a phenomenon called Rayleigh scattering. Shorter blue wavelengths scatter more than red ones.\",\n    \"Gravity is a force that attracts objects with mass toward each other. Earth pulls objects towards its center due to gravity.\",\n    \"Rainbows occur when sunlight is both refracted and reflected inside raindrops, separating the light into different colors.\",\n    \"Light travels faster than sound, so we see lightning before we hear thunder.\",\n    \"Plants make food through photosynthesis, using sunlight, water, and carbon dioxide to produce energy and oxygen.\",\n    \"We sleep to allow the body and brain to rest, recover, and process information from the day.\",\n    \"Photosynthesis is the process plants use to convert sunlight into energy using chlorophyll, water, and carbon dioxide.\",\n    \"The internet is a global network of computers that communicate via protocols like TCP/IP to exchange data.\",\n    \"Birds migrate to find better food sources, breeding grounds, or climates that are more suitable during different seasons.\"\n]\n\nbleu_scores = []\n\nfor i in range(10):\n    input_text = input_texts[i]\n    reference = reference_answers[i]\n\n    input_ids = tokenizer.encode(input_text, return_tensors=\"pt\").to(device)\n\n    output = model_for_generation.generate(\n        input_ids,\n        max_length=150,\n        num_return_sequences=1,\n        temperature=0.7,\n        pad_token_id=tokenizer.eos_token_id\n    )\n\n    generated_response = tokenizer.decode(output[0], skip_special_tokens=True)\n    \n    candidate = generated_response.split()\n    reference_tokens = [reference.split()]\n\n    score = sentence_bleu(reference_tokens, candidate, weights=(0.25, 0.25, 0.25, 0.25), smoothing_function=smoothie)\n    bleu_scores.append(score)\n\n    print(f\"\\nPrompt {i+1}: {input_text}\")\n    print(f\"Generated: {generated_response}\")\n    print(f\"Reference: {reference}\")\n    print(f\"BLEU-4 Score: {score:.4f}\")\n\nprint(\"\\nAverage BLEU-4 Score across all prompts: %.4f\" % (sum(bleu_scores) / len(bleu_scores)))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T20:03:54.165419Z","iopub.execute_input":"2025-06-09T20:03:54.165669Z","iopub.status.idle":"2025-06-09T20:04:45.655977Z","shell.execute_reply.started":"2025-06-09T20:03:54.165648Z","shell.execute_reply":"2025-06-09T20:04:45.655380Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n  warnings.warn(\nThe attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","output_type":"stream"},{"name":"stdout","text":"\nPrompt 1: So light is made up of colors?\nGenerated: So light is made up of colors? Yes, it is. Light is made up of different colors of light. So what does that mean? Well, when you look at a light source, like the sun, it's made up of different colors of light. The colors of light are called wavelengths. So when you look at the sun, it's made up of different colors of light? Yes, that's right. The colors of light are called wavelengths. So what does that mean? Well, when you look at the sun, it's made up of different colors of light. The colors of light are called wavelengths. So when you look at the sun, it'\nReference: Yes, light is made up of different colors. When they combine, they appear white. This can be separated with prisms, for example.\nBLEU-4 Score: 0.0417\n\nPrompt 2: Why is the sky blue?\nGenerated: Why is the sky blue? It's because of the sun. The sun is the reason why the sky is blue. But why is the sun blue? It's because of the color of the light that the sun emits. The light is blue because it has a certain wavelength that is absorbed by the water molecules in the air. So the sun is blue because it emits light with a certain wavelength that is absorbed by the water molecules in the air. That makes sense. So the sun is blue because it's emitting light with a certain wavelength that is absorbed by the water molecules in the air. That's right. The sun is blue because it em\nReference: The sky appears blue due to a phenomenon called Rayleigh scattering. Shorter blue wavelengths scatter more than red ones.\nBLEU-4 Score: 0.0044\n\nPrompt 3: How does gravity work?\nGenerated: How does gravity work? It's a force that pulls objects towards the Earth. That's right. But why does it work that way? Well, gravity is a result of the Earth's mass and the force of the Earth's gravity. When an object is pulled towards the Earth, it's because the Earth's gravity is pulling on it. So, if you want to understand gravity, you have to understand the Earth's gravity. That makes sense. So, if I want to understand gravity, I have to understand the Earth's gravity? Yes, that's right. The Earth's gravity is what makes everything on Earth move. Without it, we wouldn't be able to walk\nReference: Gravity is a force that attracts objects with mass toward each other. Earth pulls objects towards its center due to gravity.\nBLEU-4 Score: 0.0254\n\nPrompt 4: What causes rainbows?\nGenerated: What causes rainbows? Rainbows are caused by the reflection of light off water droplets. When sunlight hits a raindrop, it bounces off the droplet and reflects back into the air. The light then hits the air and bounces back into the sky, creating the rainbow. That's really interesting! I've never seen a rainbow before. Yeah, it's really cool. I've seen them in movies, but they always seem to be really bright and colorful. It's amazing how nature can create such beautiful things. Yeah, it's definitely awe-inspiring. I'm glad I could help you understand it\nReference: Rainbows occur when sunlight is both refracted and reflected inside raindrops, separating the light into different colors.\nBLEU-4 Score: 0.0056\n\nPrompt 5: Why do we see lightning before thunder?\nGenerated: Why do we see lightning before thunder? It's because lightning is a warning of impending thunderstorms. When lightning strikes, it creates a spark that can travel through the air and reach the ground. This spark can then create a cloud of electricity that can travel through the air and reach the ground. So when you see lightning before thunder, it's a sign that a storm is coming. That makes sense. I've always wondered why there's always lightning before thunder. It's like the universe is trying to warn us of impending doom. Yeah, I guess you're right. It's like the universe is trying to tell us\nReference: Light travels faster than sound, so we see lightning before we hear thunder.\nBLEU-4 Score: 0.0226\n\nPrompt 6: How do plants make food?\nGenerated: How do plants make food? They use photosynthesis to convert sunlight into energy. When a plant absorbs sunlight, it uses the energy to split water molecules into oxygen and hydrogen. The oxygen is released into the air, while the hydrogen is used to make glucose, which is the main source of energy for the plant. The plant then uses the glucose to make food for itself and other plants. That's really interesting! I had no idea plants could do that. Yeah, it's really cool. I'm glad I could help you understand it better. Thank you! I'm glad I could help. It's not always easy to understand, but I'\nReference: Plants make food through photosynthesis, using sunlight, water, and carbon dioxide to produce energy and oxygen.\nBLEU-4 Score: 0.0088\n\nPrompt 7: Why do we sleep?\nGenerated: Why do we sleep? To rest our minds and bodies. And why do we wake up? To start our day and get ready for the day ahead. But why do we need to sleep and wake up? To stay healthy and to be able to function properly. So, why do we need to sleep and wake up? To stay healthy and to be able to function properly. So, why do we need to sleep and wake up? To stay healthy and to be able to function properly. So, why do we need to sleep and wake up? To stay healthy and to be able to function properly. So, why do we need to sleep and wake up? To stay healthy and\nReference: We sleep to allow the body and brain to rest, recover, and process information from the day.\nBLEU-4 Score: 0.0045\n\nPrompt 8: What is photosynthesis?\nGenerated: What is photosynthesis? It's the process by which plants and other organisms convert light energy into chemical energy. Light energy is converted into chemical energy through the process of photosynthesis. So, plants use light energy to make food. That's right. Plants use light energy to make food. So, they can't live without it. Yes, they can't live without it. But they can survive without it for a while. They can survive without light for a while. But they can't survive without it for long. Yes, they can't survive without it for long. So, plants have to have light to survive. That's right. They have to\nReference: Photosynthesis is the process plants use to convert sunlight into energy using chlorophyll, water, and carbon dioxide.\nBLEU-4 Score: 0.0117\n\nPrompt 9: How does the internet work?\nGenerated: How does the internet work? It's a network of computers that are connected to each other. Each computer has a unique address, and when you type in a website's address, the computer that has that address will send you to that website. That's really interesting! I've always wondered how the internet works. Yeah, it's really cool. I can't believe how many different websites are out there. There are so many different websites! Yeah, it's really amazing. I can't believe how many different things are on the internet. There are so many different things on the internet! Yeah, it's really cool. I can't believe how many different things are on the\nReference: The internet is a global network of computers that communicate via protocols like TCP/IP to exchange data.\nBLEU-4 Score: 0.0235\n\nPrompt 10: Why do birds migrate?\nGenerated: Why do birds migrate? They migrate because they need to find food and a place to rest. They need to travel long distances to find food and to rest. That's true. But why do they migrate in the first place? Well, birds migrate because they need to find food and a place to rest. They need to travel long distances to find food and to rest. That's right. But why do they need to migrate? Well, birds migrate because they need to find food and a place to rest. They need to travel long distances to find food and to rest. That's true. But why do they need to migrate? Well, birds migrate because they need to find food\nReference: Birds migrate to find better food sources, breeding grounds, or climates that are more suitable during different seasons.\nBLEU-4 Score: 0.0070\n\nAverage BLEU-4 Score across all prompts: 0.0155\n","output_type":"stream"}],"execution_count":17},{"cell_type":"markdown","source":"# DPO","metadata":{}},{"cell_type":"code","source":"# import os\n# os.environ[\"WANDB_API_KEY\"] = \"946e923f7717c88464dc01b43cdcb664b74b23b6\"\n# from trl import DPOConfig, DPOTrainer\n\n# Sft_model = AutoModelForCausalLM.from_pretrained('TinyLlama-new-1000', torch_dtype=torch.bfloat16).to(device)\n# tokenizer = AutoTokenizer.from_pretrained(\"TinyLlama-new-1000\")\n# train_dataset = load_dataset(\"trl-lib/ultrafeedback_binarized\", split=\"train\")\n# train_dataset = train_dataset.select(range(500))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T20:04:45.656624Z","iopub.execute_input":"2025-06-09T20:04:45.656798Z","iopub.status.idle":"2025-06-09T20:04:45.660192Z","shell.execute_reply.started":"2025-06-09T20:04:45.656784Z","shell.execute_reply":"2025-06-09T20:04:45.659444Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"# Sft_model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T20:04:45.660779Z","iopub.execute_input":"2025-06-09T20:04:45.660964Z","iopub.status.idle":"2025-06-09T20:04:45.675090Z","shell.execute_reply.started":"2025-06-09T20:04:45.660949Z","shell.execute_reply":"2025-06-09T20:04:45.674342Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"# training_args = DPOConfig(\n#     per_device_train_batch_size=1,  # Reduce batch size\n#     remove_unused_columns=False,\n#     max_length=150,  # Reduce sequence length if possible\n#     max_prompt_length=256,\n#     bf16 = True,  # To maintain effective batch size\n#     dataloader_num_workers=0,\n# )\n\n\n# trainer = DPOTrainer(model=Sft_model, args=training_args, processing_class=tokenizer, train_dataset=train_dataset)\n# trainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T20:04:45.675714Z","iopub.execute_input":"2025-06-09T20:04:45.675928Z","iopub.status.idle":"2025-06-09T20:04:45.690293Z","shell.execute_reply.started":"2025-06-09T20:04:45.675914Z","shell.execute_reply":"2025-06-09T20:04:45.689798Z"}},"outputs":[],"execution_count":20}]}